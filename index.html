<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Sleek AI Voice Assistant</title>

    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

    <script src="https://cdn.tailwindcss.com"></script>

    <style>
        /* ===============================
           Custom CSS for Sleek Design and Animations
           =============================== */
        :root {
            --color-bg-dark: #0f172a; /* Slate-900 */
            --color-accent-blue: #3b82f6; /* Blue-500 */
            --color-accent-teal: #14b8a6; /* Teal-500 */
            --color-glass: rgba(255, 255, 255, 0.1); /* Slightly more opaque glass */
            --color-text-light: #f8fafc; /* Slate-50 */
            --color-shadow-light: rgba(59, 130, 246, 0.3);
            --pulse-duration: 1.5s;
        }

        body {
            font-family: 'Inter', sans-serif;
            background: var(--color-bg-dark);
            color: var(--color-text-light);
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            margin: 0;
            overflow-x: hidden; /* Prevent horizontal scroll */
            padding: 20px;
            box-sizing: border-box;
        }

        /* --- Main Container --- */
        .assistant-container {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 40px;
            text-align: center;
            width: 100%;
            max-width: 500px; /* Increased max width for desktop display */
            padding-top: 20px;
        }
        
        /* Heading */
        .assistant-container h1 {
            font-size: 2.25rem; /* Larger heading */
        }


        /* --- Status Message --- */
        .status-message {
            min-height: 2.5em; 
            transition: all 0.3s ease;
            font-weight: 500;
            opacity: 0.8;
            color: var(--color-text-light);
        }

        /* --- AI Bubble (Mic Button) --- */
        .ai-bubble {
            position: relative;
            width: 140px;
            height: 140px;
            border-radius: 50%;
            display: flex;
            justify-content: center;
            align-items: center;
            cursor: pointer;
            background: var(--color-accent-blue);
            transition: all 0.3s cubic-bezier(0.25, 0.46, 0.45, 0.94);
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            border: 3px solid transparent;
            z-index: 10;
        }

        /* Hover effect */
        .ai-bubble:not(.active):hover {
            transform: scale(1.05);
            background: #60a5fa; /* Blue-400 */
        }
        
        /* Focus state */
        .ai-bubble:focus {
            outline: none;
            border-color: var(--color-accent-teal);
        }

        /* Active State (Listening/Speaking/Thinking) */
        .ai-bubble.active {
            background: var(--color-accent-teal);
            transform: scale(0.95);
            /* Updated shadow for a deeper glow effect */
            box-shadow: 0 0 0 8px rgba(20, 184, 166, 0.4), 0 0 25px rgba(20, 184, 166, 0.8);
        }

        /* Microphone Icon */
        .mic-icon {
            width: 50px;
            height: 50px;
            color: var(--color-text-light);
            transition: transform 0.3s ease;
        }

        .ai-bubble.active .mic-icon {
            transform: scale(0.8);
        }

        /* --- Pulse Animation (Ambient Glow) --- */
        .pulse-effect {
            position: absolute;
            top: 50%;
            left: 50%;
            width: 100%;
            height: 100%;
            background-color: var(--color-accent-blue);
            border-radius: 50%;
            opacity: 0;
            transform: translate(-50%, -50%);
            z-index: 9;
        }

        .ai-bubble.active .pulse-effect {
            animation: pulse-out var(--pulse-duration) infinite;
        }

        @keyframes pulse-out {
            0% { transform: translate(-50%, -50%) scale(1); opacity: 0.8; }
            100% { transform: translate(-50%, -50%) scale(1.8); opacity: 0; }
        }

        /* --- Wave Visualizer (Listening) --- */
        .waves {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 100%;
            height: 100%;
            border-radius: 50%;
            pointer-events: none;
            opacity: 0;
            transition: opacity 0.5s ease;
            z-index: 8;
        }

        .waves.visible {
            opacity: 1;
        }

        .wave {
            position: absolute;
            width: 100%;
            height: 100%;
            border: 1px solid var(--color-accent-teal);
            border-radius: 50%;
            opacity: 0;
            animation: wave-spread 2s infinite cubic-bezier(0.66, 0.0, 0.44, 1);
        }

        .wave:nth-child(2) { animation-delay: 0.5s; }
        .wave:nth-child(3) { animation-delay: 1.0s; }

        @keyframes wave-spread {
            0% { transform: scale(1); opacity: 1; border-width: 2px; }
            100% { transform: scale(3.5); opacity: 0; border-width: 0.5px; }
        }
        
        /* Stop Button Styling */
        .btn-stop {
            padding: 10px 20px;
            border-radius: 9999px; 
            background: var(--color-accent-blue);
            color: var(--color-text-light);
            font-weight: 500;
            transition: all 0.2s ease;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.2);
            display: flex;
            align-items: center;
            gap: 8px;
            border: none;
            cursor: pointer;
        }

        .btn-stop:hover {
            background: #60a5fa;
            transform: translateY(-2px);
            box-shadow: 0 6px 15px rgba(0, 0, 0, 0.3);
        }

        .btn-stop.hidden {
            visibility: hidden;
            opacity: 0;
            transform: translateY(10px);
        }

        /* --- Response Box (Glassmorphism & New Look) --- */
        .response-box {
            background: var(--color-glass);
            backdrop-filter: blur(15px); /* Increased blur */
            border: 1px solid rgba(255, 255, 255, 0.2); /* Stronger border */
            border-radius: 16px; /* Slightly more rounded corners */
            padding: 25px; /* Increased padding */
            width: 100%;
            max-width: 500px; 
            min-height: 140px; /* Increased min height */
            text-align: left;
            opacity: 0;
            transform: translateY(20px);
            transition: all 0.5s ease-out;
            box-shadow: 0 12px 40px 0 rgba(31, 38, 135, 0.4); /* Stronger shadow */
        }

        .response-box.visible {
            opacity: 1;
            transform: translateY(0);
        }
        
        .response-title {
            font-size: 1.25rem; /* Larger title */
            font-weight: 700;
            color: var(--color-accent-teal);
            margin-bottom: 12px;
            border-bottom: 2px solid rgba(20, 184, 166, 0.3); /* Subtle separator */
            padding-bottom: 5px;
        }
        
        .response-content {
            font-size: 1rem; /* Slightly larger text */
            line-height: 1.6;
            color: var(--color-text-light);
            opacity: 0.95;
            min-height: 50px; /* Ensure space for content */
        }
        
        /* --- Typing Cursor Animation --- */
        #responseContent::after {
            content: '';
            display: inline-block;
            width: 4px;
            height: 1.2em;
            background-color: var(--color-accent-teal);
            margin-left: 4px;
            vertical-align: middle;
            animation: blink-cursor 0.7s infinite;
            opacity: 0; /* Default hidden */
        }

        /* Show cursor only when typing/thinking */
        .is-typing #responseContent::after {
            opacity: 1;
        }

        @keyframes blink-cursor {
            0%, 100% { opacity: 1; }
            50% { opacity: 0; }
        }

        /* ===============================
           Mobile Responsiveness
           =============================== */
        @media (max-width: 600px) {
            .assistant-container {
                gap: 30px;
                max-width: 90%; /* Use more screen space */
            }
            .assistant-container h1 {
                font-size: 2rem;
            }
            .ai-bubble {
                width: 120px;
                height: 120px;
            }
            .mic-icon {
                width: 40px;
                height: 40px;
            }
            .response-box {
                min-height: 120px;
                padding: 20px;
                border-radius: 12px;
            }
            .response-title {
                 font-size: 1.1rem;
            }
            .response-content {
                font-size: 0.95rem;
            }
        }
    </style>
</head>
<body>

    <section class="assistant-container">
        <h1 class="text-3xl font-bold mb-4">Sleek Voice AI</h1>

        <p id="statusMessage" class="status-message">
            Tap to start recording...
        </p>

        <div class="relative flex justify-center items-center w-40 h-40">
            <button id="aiBubble" class="ai-bubble" aria-label="Start Voice Assistant" aria-pressed="false">
                <div class="pulse-effect"></div>

                <svg class="mic-icon" fill="currentColor" viewBox="0 0 256 256">
                    <path d="M128,176a48,48,0,0,0,48-48V64a48,48,0,0,0-96,0v64A48,48,0,0,0,128,176ZM96,64a32,32,0,0,1,64,0v64a32,32,0,0,1-64,0Z"></path>
                    <path d="M208,128a8,8,0,0,1-16,0,64,64,0,0,0-128,0,8,8,0,0,1-16,0,80,80,0,0,1,72-80V32a8,8,0,0,1,16,0V48A80,80,0,0,1,208,128Z"></path>
                    <path d="M168,200a8,8,0,0,1-8,8H96a8,8,0,0,1-8-8,8,8,0,0,1,8-8h64A8,8,0,0,1,168,200Z"></path>
                </svg>

                <div id="waves" class="waves">
                    <div class="wave"></div>
                    <div class="wave"></div>
                    <div class="wave"></div>
                </div>
            </button>
        </div>

        <button id="stopBtn" class="btn-stop hidden" aria-hidden="true">
            <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><rect x="6" y="6" width="12" height="12" rx="1"/></svg>
            Stop
        </button>

        <div id="responseBox" class="response-box">
            <div class="response-title">AI Response</div>
            <p id="responseContent" class="response-content">The AI response will appear here after processing.</p>
        </div>

    </section>

    <script>
        // --- Configuration ---   
        const BACKEND_URL = ''; 
        // ASSISTANT_VOICE is no longer used as TTS is done on the server
        const TYPING_SPEED = 20; // Milliseconds per character for typing effect

        // Use an object to manage all state variables and UI elements
        const AppState = {
            STATUS_IDLE: 'Tap to start speaking...',
            STATUS_STT: 'Listening... (Speak now)', 
            STATUS_THINKING: 'Thinking... Please wait.',
            STATUS_SPEAKING: 'AI Speaking... Tap Stop to interrupt.',
            
            ui: {
                aiBubble: document.getElementById('aiBubble'),
                waves: document.getElementById('waves'),
                stopBtn: document.getElementById('stopBtn'),
                statusMessage: document.getElementById('statusMessage'),
                responseBox: document.getElementById('responseBox'),
                responseContent: document.getElementById('responseContent'),
            },
            
            // State tracking
            isListening: false, 
            isSpeaking: false,
            isTyping: false, // State for typing animation
            recognition: null, 
            typingIntervalId: null, // To store the typing interval for interruption
            currentAudio: null, // NEW: To hold the currently playing Audio object for the stream
        };

        // --- State Management and UI Updates ---

        function updateUI(status, error = null) {
            AppState.ui.statusMessage.textContent = error ? `ERROR: ${error}` : status;

            const isActive = status !== AppState.STATUS_IDLE || error;
            const isListening = status === AppState.STATUS_STT;
            // isSpeaking is now controlled by the new audio object state
            const isSpeakingOrThinking = AppState.isSpeaking || status === AppState.STATUS_THINKING || AppState.isTyping; 
            
            // Toggle Main Bubble Active State (Pulse)
            AppState.ui.aiBubble.classList.toggle('active', isActive && !error);
            AppState.ui.aiBubble.setAttribute('aria-pressed', String(isActive));
            
            // Toggle Waves (Listening Visualizer)
            AppState.ui.waves.classList.toggle('visible', isListening);
            
            // Toggle Stop Button (Show if we are busy in any way)
            AppState.ui.stopBtn.classList.toggle('hidden', !isActive);
            AppState.ui.stopBtn.setAttribute('aria-hidden', String(!isActive));

            // Show/Hide Response Box
            AppState.ui.responseBox.classList.toggle('visible', isSpeakingOrThinking || AppState.isTyping);
            
            // Toggle Typing Cursor (Only show when thinking/typing)
            const showCursor = status === AppState.STATUS_THINKING || AppState.isTyping;
            AppState.ui.responseContent.parentElement.classList.toggle('is-typing', showCursor);


            // Change bubble background based on state
            if (error) {
                AppState.ui.aiBubble.style.backgroundColor = '#ef4444'; // Red for error
            } else if (isSpeakingOrThinking) {
                 // Use accent teal for thinking/speaking
                AppState.ui.aiBubble.style.backgroundColor = 'var(--color-accent-teal)';
            } else {
                // Use accent blue for idle/listening
                AppState.ui.aiBubble.style.backgroundColor = 'var(--color-accent-blue)';
            }

            // Play tones for feedback
            if (status === AppState.STATUS_STT && !AppState.isListening) playClickTone();
            // Only play end tone if completely idle
            if (status === AppState.STATUS_IDLE && !AppState.isListening && !AppState.isSpeaking && !AppState.isTyping) playEndTone();
        }

        // --- Core Assistant Logic: Start STT (Web Speech API) ---

        function startListening() {
            if (AppState.isListening || AppState.isSpeaking || AppState.isTyping) return;

            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                updateUI(AppState.STATUS_IDLE, 'Speech Recognition is not supported (Try Chrome or Edge).');
                return;
            }

            // Clear previous content
            AppState.ui.responseContent.textContent = "Processing your request..."; 
            AppState.ui.responseBox.classList.remove('visible'); // Hide box briefly on new start

            AppState.recognition = new SpeechRecognition();
            AppState.recognition.continuous = false; 
            AppState.recognition.interimResults = false;
            AppState.recognition.lang = 'en-US'; 

            AppState.recognition.onstart = () => {
                AppState.isListening = true;
                updateUI(AppState.STATUS_STT);
            };

            AppState.recognition.onresult = (event) => {
                const last = event.results.length - 1;
                const transcript = event.results[last][0].transcript;
                console.log("Transcript:", transcript);
                
                handleChat(transcript); 
            };

            AppState.recognition.onerror = (event) => {
                console.error('STT Error:', event.error);
                if (event.error !== 'no-speech' && event.error !== 'aborted') {
                    updateUI(AppState.STATUS_IDLE, `STT Error: ${event.error}.`);
                } else if (event.error === 'no-speech') {
                    updateUI(AppState.STATUS_IDLE, 'No clear speech detected. Tap to try again.');
                }
            };

            AppState.recognition.onend = () => {
                AppState.isListening = false;
                // Only go to IDLE if thinking/speaking/typing hasn't started yet
                if (AppState.ui.statusMessage.textContent === AppState.STATUS_STT) {
                     updateUI(AppState.STATUS_IDLE, 'Listening ended (No result).');
                }
            };

            AppState.recognition.start();
        }

        function stopListening() {
            if (AppState.isListening && AppState.recognition) {
                AppState.recognition.stop();
            }
        }
        
        // --- NEW TTS (ElevenLabs Streaming) Logic ---
        
        // Function to play the streamed MP3 audio
        function playAudioStream(url) {
            return new Promise((resolve, reject) => {
                // Ensure any previous audio is stopped
                stopSpeaking(); 
                
                AppState.currentAudio = new Audio(url);
                
                AppState.currentAudio.onplay = () => {
                    AppState.isSpeaking = true;
                    updateUI(AppState.STATUS_SPEAKING);
                };

                AppState.currentAudio.onerror = (e) => {
                    console.error('Audio playback error:', e);
                    AppState.isSpeaking = false;
                    AppState.currentAudio = null;
                    // Check if the source is the 405 error page.
                    if (AppState.ui.statusMessage.textContent.includes('405')) {
                       reject(new Error('Server communication failed (405). Check server console.'));
                    } else {
                       reject(new Error('Failed to play audio stream.'));
                    }
                };
                
                // Resolve the promise when the audio finishes playing
                AppState.currentAudio.onended = () => {
                    console.log("Audio playback finished.");
                    AppState.isSpeaking = false;
                    AppState.currentAudio = null;
                    if (!AppState.isTyping) {
                        updateUI(AppState.STATUS_IDLE); // Go back to idle when audio AND typing are done
                    }
                    resolve();
                };
                
                // Start loading and playing the stream immediately
                AppState.currentAudio.load();
                AppState.currentAudio.play().catch(e => {
                    // Catch promise rejection if user hasn't interacted with the page yet
                    console.error('Audio play() failed (often due to browser autoplay policy):', e);
                });
            });
        }


        function stopSpeaking() {
            if (AppState.currentAudio) {
                AppState.currentAudio.pause();
                AppState.currentAudio.currentTime = 0;
                AppState.currentAudio = null;
                AppState.isSpeaking = false;
                
                // Transition to IDLE only if typing is also finished
                if (!AppState.isTyping) {
                   updateUI(AppState.STATUS_IDLE);
                }
                console.log("Speaking manually stopped.");
            }
        }
        
        // --- Typing Animation Logic (Updated to be interruptible) ---
        function typeResponseText(fullText) {
            // Stop any existing typing process
            if(AppState.typingIntervalId) clearInterval(AppState.typingIntervalId); 
            
            AppState.isTyping = true;
            AppState.ui.responseContent.textContent = ''; // Clear content for typing
            AppState.ui.responseBox.classList.add('visible'); // Ensure box is visible
            
            // Set status to speaking/thinking so the UI changes to the teal color and cursor shows
            updateUI(AppState.STATUS_SPEAKING); 

            let charIndex = 0;
            
            // Store the interval ID
            AppState.typingIntervalId = setInterval(() => {
                if (charIndex < fullText.length) {
                    AppState.ui.responseContent.textContent += fullText.charAt(charIndex);
                    charIndex++;
                } else {
                    // Typing finished
                    clearInterval(AppState.typingIntervalId);
                    AppState.isTyping = false;
                    
                    // Once typing is done, transition to IDLE only if speaking is also finished
                    if (!AppState.isSpeaking) {
                       updateUI(AppState.STATUS_IDLE);
                    }
                }
            }, TYPING_SPEED);
        }
        
        // --- Combined Backend Communication (Fixes 405 Error) ---
        async function handleChat(query) {
            
            // 1. Prepare UI for thinking state
            updateUI(AppState.STATUS_THINKING);
            
            // Clear any old typing interval just in case
            if (AppState.typingIntervalId) {
                clearInterval(AppState.typingIntervalId);
                AppState.isTyping = false;
            }

            try {
                // *** CRITICAL FIX: The endpoint must be /api/chat ***
                const response = await fetch(`${BACKEND_URL}/api/chat`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json' 
                    },
                    body: JSON.stringify({ query: query }) 
                });

                if (!response.ok) {
                    // If the server returns a non-OK status, it's not an audio stream
                    let errorDetails = `Server responded with status ${response.status}.`;
                    try {
                        const errorJson = await response.json();
                        errorDetails = errorJson.error || errorDetails;
                    } catch (e) {
                        // If it fails to parse JSON, use the default message
                    }
                    throw new Error(errorDetails);
                }
                
                // --- STEP 1: Get Text and Start Typing Animation ---
                
                // Text is received via a custom header
                const encodedText = response.headers.get('X-AI-Response-Text');
                if (!encodedText) {
                    // This error indicates the server did not set the header correctly 
                    throw new Error("Missing AI response text header from server. Check server.js logic.");
                }
                const responseText = decodeURIComponent(encodedText);
                
                // Start the Typing Animation
                typeResponseText(responseText); 
                
                // --- STEP 2: Play the Audio Stream ---
                
                // The server is streaming MP3 audio, so we use the response URL as the audio source
                const audioUrl = response.url;
                
                // Wait for the audio to finish playing
                await playAudioStream(audioUrl); 

            } catch (error) {
                console.error("Chat Error:", error);
                
                // If an error occurred, stop any ongoing typing and speaking
                if (AppState.typingIntervalId) clearInterval(AppState.typingIntervalId);
                stopSpeaking(); 
                
                updateUI(AppState.STATUS_IDLE, `Chat Error: ${error.message}.`);
            }
        }
        
        // --- Event Listeners and Initialization ---

        function handleMainClick() {
            // If typing or speaking, stop everything
            if (AppState.isSpeaking || AppState.isTyping) {
                // Stop typing interval
                if (AppState.typingIntervalId) {
                    clearInterval(AppState.typingIntervalId);
                    AppState.isTyping = false;
                }
                stopSpeaking(); 
            } else if (AppState.isListening) {
                stopListening(); 
            } else {
                startListening(); 
            }
        }

        function initialize() {
            // Main Button Click
            AppState.ui.aiBubble.addEventListener('click', handleMainClick);

            // Stop Button Click
            AppState.ui.stopBtn.addEventListener('click', () => {
                // Stop speech
                stopSpeaking(); 

                // Stop typing animation/interval
                if (AppState.typingIntervalId) {
                    clearInterval(AppState.typingIntervalId);
                    AppState.isTyping = false;
                    // Immediately ensure the full text is shown (if available)
                    const fullText = AppState.ui.responseContent.textContent; 
                    AppState.ui.responseContent.textContent = fullText; 
                }
                
                // Stop listening
                if (AppState.isListening) {
                    stopListening();
                }
                
                // Final check to ensure IDLE state
                if (!AppState.isListening && !AppState.isSpeaking && !AppState.isTyping) {
                    updateUI(AppState.STATUS_IDLE);
                }
            });
            
            updateUI(AppState.STATUS_IDLE);
        }

        // --- Web Audio Tones for Feedback (Kept the same) ---
        // ... (playClickTone and playEndTone functions are unchanged) ...
        function playClickTone(){
            try{
                const ctx = new (window.AudioContext || window.webkitAudioContext)();
                const o = ctx.createOscillator();
                const g = ctx.createGain();
                o.type = 'sine';
                o.frequency.setValueAtTime(440, ctx.currentTime);
                g.gain.setValueAtTime(0.0001, ctx.currentTime);
                g.gain.exponentialRampToValueAtTime(0.06, ctx.currentTime + 0.01);
                o.connect(g); g.connect(ctx.destination);
                o.start();
                g.gain.exponentialRampToValueAtTime(0.0001, ctx.currentTime + 0.25);
                o.stop(ctx.currentTime + 0.26);
            }catch(e){ console.error("WebAudio error:", e); }
        }

        function playEndTone(){
            try{
                const ctx = new (window.AudioContext || window.webkitAudioContext)();
                const o = ctx.createOscillator();
                const g = ctx.createGain();
                o.type = 'triangle';
                o.frequency.setValueAtTime(240, ctx.currentTime);
                g.gain.setValueAtTime(0.0001, ctx.currentTime);
                g.gain.exponentialRampToValueAtTime(0.05, ctx.currentTime + 0.01);
                o.connect(g); g.connect(ctx.destination);
                o.start();
                g.gain.exponentialRampToValueAtTime(0.0001, ctx.currentTime + 0.28);
                o.stop(ctx.currentTime + 0.29);
            }catch(e){ console.error("WebAudio error:", e); }
        }

        // Start the application after the window loads
        window.onload = initialize;
    </script>
</body>
</html>